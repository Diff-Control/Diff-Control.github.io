<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="Diff-Control: Stateful Action Diffusion Policy for Imitation Learning">
  <meta name="keywords" content="Diffusion Model, Imitation Learning, Stateful Policy">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Diff-Control: A Stateful Diffusion-based Policy for Imitation Learning</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/irl_lab.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <a class="navbar-item" href="https://www.xiao-liu.me/">
          <span class="icon">
            <i class="fas fa-home"></i>
          </span>
        </a>

        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            More Research
          </a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://github.com/ir-lab/DEnKF">
              Differentiable Ensemble Kalman Filter (DEnKF)
            </a>
            <a class="navbar-item" href="https://github.com/ir-lab/soft_robot_DEnKF">
              DEnKF + soft robot and spatio-temporal embedding
            </a>
            <!-- <a class="navbar-item" href="https://latentfusion.github.io">
              LatentFusion
            </a>
            <a class="navbar-item" href="https://photoshape.github.io">
              PhotoShape
            </a> -->
          </div>
        </div>
      </div>

    </div>
  </nav>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Diff-Control: A Stateful Diffusion-based Policy for Imitation
              Learning</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://www.xiao-liu.me/">Xiao Liu</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="http://yifanzhou.com/">Yifan Zhou</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://faweigend.com/">Fabian Weigend </a><sup>1</sup>,
              </span>
              <span class="author-block">Shubham Sonawani <sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="http://www.brain.kyutech.ac.jp/~ikemoto/">Shuhei Ikemoto</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="http://henibenamor.weebly.com/">Heni Ben Amor</a><sup>1</sup>,
              </span>
              <!-- <span class="author-block">
                <a href="https://www.danbgoldman.com">Dan B Goldman</a><sup>2</sup>,
              </span> -->
              <!-- <span class="author-block">
                <a href="https://homes.cs.washington.edu/~seitz/">Steven M. Seitz</a><sup>1,2</sup>,
              </span>
              <span class="author-block">
                <a href="http://www.ricardomartinbrualla.com">Ricardo Martin-Brualla</a><sup>2</sup>
              </span> -->
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup><a
                  href="https://interactive-robotics.engineering.asu.edu/">Interactive Robotics Lab</a>, Arizona State
                University</span>
              <span class="author-block"><sup>2</sup>Kyushu Institute of Technology</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://openreview.net/forum?id=0hQMcWfjG9"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/2011.12948" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span> -->
                <!-- Video Link. -->
                <span class="link-block">
                  <a href="https://www.youtube.com/watch?v=OdBMquRUTdU"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/ir-lab/alpha-MDF"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Dataset Link.
                <span class="link-block">
                  <a href="https://github.com/google/nerfies/releases/tag/0.1"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>Data</span>
                  </a> -->
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">

        <!-- <img src="./static/videos/teaser.png" class="interpolation-image" alt="Interpolate start reference image." /> -->

        <video id="teaser" autoplay muted loop playsinline height="10%">
          <source src="./static/videos/task_sequence.mp4" type="video/mp4">
        </video>
        <h2 class="subtitle has-text-centered">

          <strong>Diff-Control Policy</strong> incorporates ControlNet, functioning as a transition model that captures
          temporal transitions within the action space to ensure action consistency.

        </h2>
      </div>
    </div>
  </section>


  <!-- <section class="hero is-light is-small">
    <div class="hero-body">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-steve">
            <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/steve.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-chair-tp">
            <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/chair-tp.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-shiba">
            <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/shiba.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-fullbody">
            <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/fullbody.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-blueshirt">
            <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/blueshirt.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-mask">
            <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/mask.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-coffee">
            <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/coffee.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-toby">
            <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/toby2.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </section> -->


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              While imitation learning provides a simple and effective framework for policy learning, how to acquire
              consistent action during robot execution remains a challenging task. Existing approaches primarily focus
              on either modifying the action representation at data curation stage or altering the model itself, both of
              which do not fully address the scalability of consistent action generation. To overcome this limitation,
              we propose the Diff-Control policy, which leverages a diffusion-based model to learn action representation
              from a state-space modeling perspective. This statefulness is achieved through a Bayesian formulation,
              instead of the naive fusion of stateful features. Our experimental results demonstrate the significance of
              incorporating action statefulness in policy learning, where Diff-Control shows improved performance across
              various tasks. Specifically, Diff-Control achieves an average success rate of 72% and 84% on stateful
              and dynamic tasks, respectively. Notably, Diff-Control also shows consistent performance in the presence
              of perturbations, outperforming other state-of-the-art methods that falter under similar conditions.
            </p>
            <!-- <p>
              We show that <span class="dnerf">Nerfies</span> can turn casually captured selfie
              photos/videos into deformable NeRF
              models that allow for photorealistic renderings of the subject from arbitrary
              viewpoints, which we dub <i>"nerfies"</i>. We evaluate our method by collecting data
              using a
              rig with two mobile phones that take time-synchronized photos, yielding train/validation
              images of the same pose at different viewpoints. We show that our method faithfully
              reconstructs non-rigidly deforming scenes and reproduces unseen views with high
              fidelity.
            </p> -->
          </div>
        </div>
      </div>
      <!--/ Abstract. -->



      <!-- Paper video. -->
      <!-- <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Video</h2>
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/OdBMquRUTdU" frameborder="0" allow="autoplay; encrypted-media"
              allowfullscreen></iframe>
          </div>
        </div>
      </div> -->
      <!--/ Paper video. -->
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">


      <!-- method. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Diff-Control Policy</h2>

          <!-- Interpolating. -->
          <h3 class="title is-4">Overview</h3>
          <div class="content has-text-justified">
            <p>
              In computer vision, <i>ControlNet</i> has demonstrated significant utility in various applications
              involving
              image and video generation using Stable Diffusion model with learned control. ControlNet acts as a
              framework that accepts additional control inputs or prior conditions and utilizes them to generate images
              or video sequences that align with the specified control input. Our method extends the application of
              ControlNet from image generation to action generation in the domain of robotics, and we utilize a
              <i>Bayesian
                formulation</i> to bridge the gap between standalone policies and state space modeling as shown in
              Figure
              below. We find that proposed Diff-Control policy effectively maintains stateful behavior by conditioning
              its actions on prior actions, resulting in consistent action generation.
            </p>
            <img src="./static/videos/controlnet.png" class="interpolation-image"
              alt="Interpolate start reference image." />
            <p>
              Diff-Control operates by generating a sequence of actions while incorporating conditioning on previously
              generated actions. In this example, the Diff-Control policy is depicted executing the "Open Lid" task. For
              instance, in the second sub-figure,
              the blue trajectory represents previous action trajectory, denoted as
              <strong>a<sub>[W<sub>t</sub>]</sub></strong>, while
              the red trajectory
              displays the newly generated sequence of actions, denoted as
              <strong>a<sub>[W<sub>t-h</sub>]</sub></strong>.
            </p>
          </div>


          <!-- Attention Gain -->
          <h3 class="title is-4">Stateful behavior</h3>
          <div class="content has-text-justified">
            <p>
              We find that proposed Diff-Control policy effectively maintains stateful behavior by conditioning its
              actions on prior actions, resulting in consistent action generation. A simple example showcasing this
              behavior is depicted in the figure below, where each policy is learning the approximation of a cosine
              function. Diff-Control policy demonstrates its capability to incorporate temporal conditioning without
              generating multiple modes compare to state-of-the-art methods.
            </p>
            <center><img src="./static/videos/sine.png" width="600" height="500"></center>
            <p>
              At a given state, Diff-Control policy can utilize prior trajectories to approximate the desired function.
              Diffusion policy learns both modes but fails on generating the correct trajectory cosistently,
              Image-BC/BC-Z fails to generate the correct trajectory.
            </p>
          </div>
          <!--/ Attention Gain -->


          <!-- result -->
          <h3 class="title is-4">Results</h3>
          <div class="content has-text-justified">
            <p>
              Predicted joint angle trajectories and the corresponding accumulated attention values for each modality.
              (a) represents the results attained from the actual robot, whereas (b) illustrates attention values for
              all modalities both with and without masking certain modalities.
            </p>
            <img src="./static/videos/result-UR5.png" class="interpolation-image"
              alt="Interpolate start reference image." />
          </div>
          <!--/ result -->

        </div>
      </div>
      <!--/ method. -->
      <div class="columns is-centered has-text-centered">
        <!-- Regid Body motion -->
        <div class="column">
          <div class="content">
            <h2 class="title is-3">Rigid Body Motion</h2>
            <p>
              We use α-MDF for monitoring the state of a UR5 robot during tabletop arrangement tasks.
            </p>
            <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/UR5.mp4" type="video/mp4">
            </video>
          </div>
        </div>
        <!--/ Regid Body motion -->

        <!-- Soft robot motion -->
        <div class="column">
          <div class="content">
            <h2 class="title is-3">Soft Robot Dynamics</h2>
            <p>
              This experiment involves implementing the
              α-MDF to model the dynamics of a soft robot system.
            </p>
            <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/Tensegrity.mp4" type="video/mp4">
            </video>
          </div>
        </div>
        <!--/ soft robot motion -->
      </div>
      <!--/ Matting. -->


      <!-- Concurrent Work. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Related Links</h2>

          <div class="content has-text-justified">
            <p>
              To assess the performance and effectiveness of our approach, we conducted comparative evaluations against
              differentiable filter baselines and sensor fusion baselines.
            </p>
            <p>
              <a href="https://arxiv.org/abs/2012.14313">How to Train Your Differentiable Filter
              </a> introduces general approcahes for building differentiable filter frameworks.
            </p>
            <p>
              <a href="https://arxiv.org/abs/1805.11122">Differentiable Particle Filters</a> introduces
              end-to-end learning with sampling method intact for filtering.
            </p>
            <p>
              Various sensor fusion strategies, including unimodal fusion and crossmodal fusion, are thoroughly
              discussed in <a href="https://arxiv.org/abs/2010.13021">Multimodal Sensor Fusion with Differentiable
                Filters</a>.
            </p>
          </div>
        </div>
      </div>
      <!--/ Concurrent Work. -->

    </div>
  </section>


  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{liu2023alphamdf,
        title = {\alpha-MDF: An Attention-based Multimodal Differentiable Filter for Robot State Estimation},
        author = {Liu, Xiao and Zhou, Yifan and Ikemoto, Shuhei and Amor, Heni Ben},
        booktitle = {7th Annual Conference on Robot Learning},
        year = {2023},
        url = {https://openreview.net/forum?id=0hQMcWfjG9},
      }</code></pre>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href="./static/videos/multimodal_learning_for_CoRL_2023.pdf">
          <i class="fas fa-file-pdf"></i>
        </a>
        <a class="icon-link" href="https://github.com/liuxiao1468" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            <p>
              This means you are free to borrow the <a href="https://github.com/Alpha-MDF/Alpha-MDF.github.io">source
                code</a> of this website,
              we just ask that you link back to this page in the footer.
              Please remember to remove the analytics code included in the header of the website which
              you do not want on your website.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>